{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "jeopardy = pd.read_csv(\"jeopardy.csv\")\n",
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove the preceding space in some of the column name\n",
    "jeopardy.columns = ['Show Number', 'Air Date', 'Round', 'Category', 'Value',\n",
    "       'Question', 'Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#define a function that \n",
    "#takes in a string, converts it to lowercase,\n",
    "#removes all punctuation in the string and returns the normalized string\n",
    "\n",
    "def normalize(string):\n",
    "    string = string.lower()\n",
    "    string = re.sub(r'[^\\w\\s]', '', string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    for the last 8 years of his life galileo was u...\n",
       "1    no 2 1912 olympian football star at carlisle i...\n",
       "2    the city of yuma in this state has a record av...\n",
       "3    in 1963 live on the art linkletter show this c...\n",
       "4    signer of the dec of indep framer of the const...\n",
       "Name: clean_question, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize the Question column\n",
    "jeopardy[\"clean_question\"] = jeopardy[\"Question\"].apply(normalize)\n",
    "jeopardy[\"clean_question\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    copernicus\n",
       "1    jim thorpe\n",
       "2       arizona\n",
       "3     mcdonalds\n",
       "4    john adams\n",
       "Name: clean_answer, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question column looks good. Now, let's normalize Answer column.\n",
    "jeopardy[\"clean_answer\"] = jeopardy[\"Answer\"].apply(normalize)\n",
    "jeopardy[\"clean_answer\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    200\n",
       "1    200\n",
       "2    200\n",
       "3    200\n",
       "4    200\n",
       "Name: clean_value, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a function to normalize dollar values - takes in string, \n",
    "#remove punctuations (note that dollar values are not fractional)\n",
    "# convert string to integer\n",
    "# if there's an error, assign zero\n",
    "#return integer value.\n",
    "def normalize_value(string):\n",
    "    string = re.sub(r'[^\\w\\s]', '', string)\n",
    "    try:\n",
    "        num = int(string)\n",
    "    except Exception:\n",
    "        num = 0\n",
    "    return num\n",
    "\n",
    "jeopardy[\"clean_value\"] = jeopardy[\"Value\"].apply(normalize_value)\n",
    "jeopardy[\"clean_value\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert \"Air Date\" column to a datetime column\n",
    "jeopardy[\"Air Date\"] = pd.to_datetime(jeopardy[\"Air Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare for our Jeopardy! game, we'll like to know if we should study past questions, general knowledge or not study at all. To do tat, it would be helpful to figure out two things:\n",
    "    * How often the answer is deducible from the question.\n",
    "    * How often new questions are repeats of older questions\n",
    "    \n",
    "To help us answer these questions, we'll do a frequency count of words in the Question and Answer columns of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def qa_match(row):#takes in a row\n",
    "    \"\"\"\n",
    "    Finds the proportion of word matches between questions and their respective answers\n",
    "    \"\"\"\n",
    "    split_answer = row[\"clean_answer\"].split()\n",
    "    split_question = row[\"clean_question\"].split()\n",
    "    match_count = 0\n",
    "    if \"the\" in split_answer:\n",
    "        split_answer.remove(\"the\")\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        for word in split_answer:\n",
    "            if word in split_question:\n",
    "                match_count += 1\n",
    "        result = match_count/len(split_answer)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count the number of times terms in clean_answer occur in clean_question\n",
    "jeopardy[\"answer_in_question\"] = jeopardy.apply(qa_match, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05900196524977763"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mean of the answer_in_question column; to get a general sense of how often it happens\n",
    "aiq_mean = jeopardy[\"answer_in_question\"].mean()\n",
    "aiq_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This calculation shows that there's about 6% of the words in the answers come directly from the question. This is a little misleading, in that we may straightaway conclude that answers do not come from the wording of questions. However, there are a few cases where all the words in the answer come from the question. We may need to segment the dataset based on those that have nonzero answer_in_question score to know if there's something we can learn about these questions that can help us in our preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# investigate the idea from the markdown above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's investigate if the show repeats questions. \n",
    "\n",
    "Because this dataset contains only about 10 percent of the full Jeopardy question dataset, we cannot do a direct comparison. However, we can track the terms used in the dataset we have and see if there are any patterns there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "question_overlap = []\n",
    "terms_used = set()\n",
    "\n",
    "jeopardy = jeopardy.sort_values(\"Air Date\")\n",
    "\n",
    "for i, row in jeopardy.iterrows():\n",
    "    split_question = row[\"clean_question\"].split()\n",
    "    split_question = [w for w in split_question if len(w) >=6] #a way of removing insignificant words\n",
    "    match_count = 0\n",
    "    for w in split_question:\n",
    "        if w in terms_used:\n",
    "            match_count += 1\n",
    "        terms_used.add(w)\n",
    "    if len(split_question) > 0:\n",
    "        match_count /=len(split_question) #turns match_count into a fraction\n",
    "    question_overlap.append(match_count)\n",
    "jeopardy[\"question_overlap\"] = question_overlap\n",
    "mean_overlap = jeopardy[\"question_overlap\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6895470512782512"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a 69% probability that a term (presumably, nontrivial words with more than five characters) used in a question has been used in a previous question. This is a very valid and, potentially, important way of preparing for the game.\n",
    "So, we could focus on this and supplement our study with patterns from cases where the answers have most of their words emanating from the corresponding questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High - Value Terms\n",
    "Let's say you only want to study questions that pertain to high value questions instead of low value questions. This will help you earn more money when you're on Jeopardy.\n",
    "\n",
    "You can actually figure out which terms correspond to high-value questions using a chi-squared test. You'll first need to narrow down the questions into two categories:\n",
    "\n",
    "    * Low value -- Any row where `Value` is less than `800`.\n",
    "    * High value -- Any row where `Value` is greater than `800`.\n",
    "You'll then be able to loop through each of the terms from the last cell, `terms_used`, and:\n",
    "\n",
    "    * Find the number of low value questions the word occurs in.\n",
    "    * Find the number of high value questions the word occurs in.\n",
    "    * Find the percentage of questions the word occurs in.\n",
    "    * Based on the percentage of questions the word occurs in, find expected counts.\n",
    "    * Compute the chi squared value based on the expected counts and the observed counts for high and low value questions.\n",
    "\n",
    "You can then find the words with the biggest differences in usage between high and low value questions, by selecting the words with the highest associated chi-squared values. Doing this for all of the words would take a very long time, so we'll just do it for a small sample now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def value_score(row):\n",
    "    \"\"\"\n",
    "    A function that tells whether us whether a column is high-valued or not\n",
    "    \"\"\"\n",
    "    if row[\"clean_value\"] > 800:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jeopardy[\"high_value\"] = jeopardy.apply(value_score, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def value_counts(word):\n",
    "    \n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for i, row in jeopardy.iterrows():\n",
    "        split_question = row[\"clean_question\"].split()\n",
    "        if word in split_question:\n",
    "            if row[\"high_value\"] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (0, 3),\n",
       " (0, 5),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (15, 44)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import choice\n",
    "\n",
    "terms_used_list = list(terms_used)\n",
    "comparison_terms = [choice(terms_used_list) for i in range(10)]\n",
    "\n",
    "observed_expected = []\n",
    "\n",
    "for term in comparison_terms:\n",
    "    v = value_counts(term)\n",
    "    observed_expected.append(v)\n",
    "\n",
    "observed_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5734\n",
      "14265\n"
     ]
    }
   ],
   "source": [
    "high_value_rows = jeopardy[jeopardy[\"high_value\"] == 1]\n",
    "low_value_rows = jeopardy[jeopardy[\"high_value\"] == 0]\n",
    "\n",
    "high_value_count = len(high_value_rows)\n",
    "low_value_count = len(low_value_rows)\n",
    "\n",
    "print(high_value_count)\n",
    "print(low_value_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "chi_squared = []\n",
    "\n",
    "for i in observed_expected:\n",
    "    total = i[0] + i[1]   #each element of observed_expected is a list\n",
    "    total_prop = total/len(jeopardy)\n",
    "    expected_high_value_count = total_prop * high_value_count\n",
    "    expected_low_value_count = total_prop * low_value_count\n",
    "    observed = np.array([i[0], i[1]])\n",
    "    expected = np.array([expected_high_value_count, expected_low_value_count])\n",
    "    chi_squared.append(chisquare(observed, expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=0.4448774816612795, pvalue=0.5047776487545996),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.803925692253768, pvalue=0.3699222378079571),\n",
       " Power_divergenceResult(statistic=1.205888538380652, pvalue=0.27214791766902047),\n",
       " Power_divergenceResult(statistic=2.00981423063442, pvalue=0.1562844540498966),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.3042931605199027, pvalue=0.5812034286869123)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi- Squared Results\n",
    "None of the terms had a significant difference between high and low-value rows. All p - values were far greater than 0.05 and all the frequencies were lower than 5. It would far better to run this tests only with terms that have higher frequencies.\n",
    "\n",
    "We may try this out with the whole dataset and see if we are able to pinpoint specific terms with significant difference between high and low value rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
